{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b382ffe-ad69-4bf0-a1eb-d1a6c59ae84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5159568-ccb5-450c-94df-edc7d1e70f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de08e8eb-7436-41ff-9b40-ad3e09ad61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the dataset\n",
    "train_dir = r'C:\\Users\\User\\.jupyter\\plant disease\\plant disease\\train'  # Update this to your actual path\n",
    "val_dir = r'C:\\Users\\User\\.jupyter\\plant disease\\plant disease\\valid'      # Update this to your actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "641d81d6-4dc9-4e9c-975f-ca527bc7e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "958f6084-7391-42d5-92d0-6006b9d2d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For validation, just rescale\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8fa131-fddb-46fc-a23f-63631c3ee8ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create generators for training and validation datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m      3\u001b[0m     train_dir,\n\u001b[0;32m      4\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m),\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      6\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m val_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     10\u001b[0m     val_dir,\n\u001b[0;32m     11\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m),\n\u001b[0;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     13\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_datagen' is not defined"
     ]
    }
   ],
   "source": [
    "# Create generators for training and validation datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44c7161a-92a0-4184-8f79-81f9bd6dbedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 5\n"
     ]
    }
   ],
   "source": [
    "# Check the number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(\"Number of classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a94f18c1-81ff-4448-89d3-fc72c0cfe9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Output layer matches number of classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0548ce7-93d8-41d6-8d5f-40eb3578dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c501527b-8aad-430d-b0e5-5bb2ba39b233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 1s/step - accuracy: 0.4342 - loss: 1.2665 - val_accuracy: 0.7812 - val_loss: 0.6245\n",
      "Epoch 2/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514us/step - accuracy: 0.7812 - loss: 0.4903 - val_accuracy: 0.8000 - val_loss: 0.4658\n",
      "Epoch 3/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 778ms/step - accuracy: 0.8090 - loss: 0.4992 - val_accuracy: 0.7943 - val_loss: 0.5957\n",
      "Epoch 4/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - accuracy: 0.9375 - loss: 0.1875 - val_accuracy: 0.6667 - val_loss: 0.9151\n",
      "Epoch 5/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 1s/step - accuracy: 0.8896 - loss: 0.3170 - val_accuracy: 0.9149 - val_loss: 0.2196\n",
      "Epoch 6/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318us/step - accuracy: 0.9375 - loss: 0.1568 - val_accuracy: 1.0000 - val_loss: 0.0664\n",
      "Epoch 7/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 784ms/step - accuracy: 0.8999 - loss: 0.2712 - val_accuracy: 0.7595 - val_loss: 0.8652\n",
      "Epoch 8/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322us/step - accuracy: 0.9062 - loss: 0.2707 - val_accuracy: 1.0000 - val_loss: 0.1629\n",
      "Epoch 9/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 907ms/step - accuracy: 0.9016 - loss: 0.2650 - val_accuracy: 0.8767 - val_loss: 0.3875\n",
      "Epoch 10/10\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - accuracy: 0.9688 - loss: 0.0748 - val_accuracy: 1.0000 - val_loss: 0.0817\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,  # Adjust the number of epochs as needed\n",
    "    steps_per_epoch=train_generator.samples // 32,\n",
    "    validation_steps=val_generator.samples // 32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab766c6d-819b-4c1e-8bd5-a0dcee4c1a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model (optional)\n",
    "model.save('tomato_disease_classifier.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72902b92-7f1e-41df-9493-d5a31301ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated dictionary for disease to pesticide recommendations\n",
    "pesticide_recommendations = {\n",
    "    'Tomato___Bacterial_spot': 'Use Copper-based fungicides',\n",
    "    'Tomato___Early_blight': 'Use Chlorothalonil or Azoxystrobin',\n",
    "    'Tomato___healthy': 'No pesticides needed',\n",
    "    'Tomato___Late_blight': 'Use Mancozeb or Ridomil',\n",
    "    'Tomato___Leaf_Mold': 'Use Potassium bicarbonate or Neem oil'\n",
    "}\n",
    "\n",
    "def recommend_pesticide(disease):\n",
    "    return pesticide_recommendations.get(disease, \"No recommendation available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2ad5fae-953b-4e49-a9a2-4c13c01c6de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Detected Disease: Tomato___Bacterial_spot\n",
      "Recommended Pesticide: Use Copper-based fungicides\n"
     ]
    }
   ],
   "source": [
    "def predict_and_recommend(image_path):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Make predictions\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    \n",
    "    # Map predicted class to disease name\n",
    "    disease_name = list(train_generator.class_indices.keys())[predicted_class[0]]\n",
    "    \n",
    "    # Get pesticide recommendation\n",
    "    pesticide = recommend_pesticide(disease_name)\n",
    "    \n",
    "    return disease_name, pesticide\n",
    "\n",
    "# Example usage\n",
    "image_path = r'C:\\Users\\User\\.jupyter\\plant disease\\plant disease\\train\\Tomato___Bacterial_spot\\0e94696b-3e0d-4d4c-a712-01197e228cf1___UF.GRC_BS_Lab Leaf 8641.JPG'  # Update this to your actual test image path\n",
    "disease, pesticide = predict_and_recommend(image_path)\n",
    "print(f'Detected Disease: {disease}\\nRecommended Pesticide: {pesticide}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64276ac6-fde3-4d48-80c3-2afd8b4f90eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
